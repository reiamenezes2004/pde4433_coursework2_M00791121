{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5e0dd5e-a84d-4966-b31c-9070d06236f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required modules\n",
    "import os, json, csv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, Label, Button\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85f4fbb3-9336-4178-be9b-06775e6259f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"plates\"  #path containing the Dubai number plates\n",
    "img_height = 224 \n",
    "img_width = 224\n",
    "batch_size = 32  #number of images processing in one training batch\n",
    "epochs = 15  #training iterations\n",
    "model_path = \"trained_dubai_model.keras\"    #poth to save the trained model\n",
    "class_names_path = \"dubai_class_names.json\"   #store the class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3e443ae-9757-4bf0-8016-bfd35a544023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 348 files belonging to 10 classes.\n",
      "Using 279 files for training.\n",
      "Found 348 files belonging to 10 classes.\n",
      "Using 69 files for validation.\n",
      "Dubai Plate Classes: ['C5038', 'D77988', 'H79111', 'I9269', 'Q5121', 'R6729', 'S3227', 'S3601', 'U8804', 'X89099']\n"
     ]
    }
   ],
   "source": [
    "#loading dataset as 80% for training\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split=0.2,    #20% reserved for testing\n",
    "    subset=\"training\",\n",
    "    seed=123,    #consistent date shuffling\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "#loading dataset as 20% for testing\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(\"Dubai Plate Classes:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0169994-75ac-4fc9-adcb-56f27a8b4393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance optimization\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "#augmentation layer\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomContrast(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72fbdc2-f6ea-4771-bc76-dd45194541c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
